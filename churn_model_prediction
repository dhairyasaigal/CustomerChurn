import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler 
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
from imblearn.over_sampling import SMOTE
import pickle
import os

# Load and preprocess dataset
def load_data(path):
    print(f"Attempting to load data from: {path}") 
    df = pd.read_csv(path)
    df = df.drop(columns=["customerID"])
    df["TotalCharges"] = df["TotalCharges"].replace(" ", "0.0").astype(float)
    df["Churn"] = df["Churn"].replace({"Yes": 1, "No": 0})
    return df

# Encode categorical columns and save encoders
def encode_features(df):
    encoders = {}
    object_cols = df.select_dtypes(include="object").columns
    for col in object_cols:
        enc = LabelEncoder()
        df[col] = enc.fit_transform(df[col])
        encoders[col] = enc
    return df, encoders

# Scale numerical features
def scale_features(X_train, X_test):
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    return X_train_scaled, X_test_scaled, scaler

# Train multiple models and evaluate
def train_models(X_train, y_train):
    models = {
        "Decision Tree": DecisionTreeClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42),
        "Logistic Regression": LogisticRegression(max_iter=5000),
        "SVM": SVC(probability=True),
        "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
        results[name] = {
            "model": model,
            "cv_score": np.mean(scores)
        }
        print(f"{name} CV Accuracy: {np.mean(scores):.4f}")
    return results

# Grid Search on the best model (Random Forest)
def tune_hyperparameters(X, y):
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [5, 10, None],
        'min_samples_split': [2, 5]
    }
    grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='accuracy')
    grid.fit(X, y)
    print("Best Parameters from GridSearch:", grid.best_params_)
    return grid.best_estimator_

# Evaluate on test set
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    print("\nTest Evaluation:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))

# Plot feature importance for tree-based models
def plot_feature_importance(model, features):
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        sorted_idx = np.argsort(importances)[::-1]
        plt.figure(figsize=(10,6))
        plt.bar(range(len(importances)), importances[sorted_idx], align="center")
        plt.xticks(range(len(importances)), [features[i] for i in sorted_idx], rotation=90)
        plt.title("Feature Importances")
        plt.tight_layout()
        plt.show()

# Save model and encoders
def save_artifacts(model, feature_names, encoders, out_dir="models"):
    os.makedirs(out_dir, exist_ok=True)
    with open(os.path.join(out_dir, "best_model.pkl"), "wb") as f:
        pickle.dump({"model": model, "features": feature_names}, f)
    with open(os.path.join(out_dir, "encoders.pkl"), "wb") as f:
        pickle.dump(encoders, f)

# Predict using raw input
def predict_input(raw_input_dict, model_path="models/best_model.pkl", encoder_path="models/encoders.pkl"):
    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)
    with open(encoder_path, 'rb') as f:
        encoders = pickle.load(f)
    model = model_data['model']
    features = model_data['features']

    input_df = pd.DataFrame([raw_input_dict])
    for col in input_df.columns:
        if col in encoders:
            input_df[col] = encoders[col].transform(input_df[col])

    input_df = input_df[features]
    pred = model.predict(input_df)[0]
    prob = model.predict_proba(input_df)[0][1]
    return pred, prob


if __name__ == "__main__":
    # Load data
    data_path = "/content/sample_data/WA_Fn-UseC_-Telco-Customer-Churn.csv"
    df = load_data(data_path)

    df, encoders = encode_features(df)

    X = df.drop(columns=["Churn"])
    y = df["Churn"]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Scale features
    X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)

    smote = SMOTE(random_state=42)
    X_train_sm, y_train_sm = smote.fit_resample(X_train_scaled, y_train) # Use scaled data for SMOTE

    results = train_models(X_train_sm, y_train_sm)

    best_model_name = max(results, key=lambda k: results[k]['cv_score'])
    best_model = results[best_model_name]['model']
    print(f"\nBest model: {best_model_name}")

    best_model = tune_hyperparameters(X_train_sm, y_train_sm)
    evaluate_model(best_model, X_test_scaled, y_test) # Evaluate on scaled test data
    plot_feature_importance(best_model, X.columns.tolist())
    save_artifacts(best_model, X.columns.tolist(), encoders)
